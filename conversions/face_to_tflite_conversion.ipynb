{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "print(device)\n",
    "\n",
    "sys.path.append(\"/Users/osinachinwogu/Documents/cybertruck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/osinachinwogu/miniforge3/envs/projenv/lib/python3.9/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name xception to current legacy_xception.\n",
      "  model = create_fn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cnn.face_cnn import Face_CNN\n",
    "import torch.onnx\n",
    "\n",
    "\n",
    "face_model = Face_CNN(None).to(device)\n",
    "x = torch.randn(5, 3, 299, 299).to(device)\n",
    "face_model.load_state_dict(\n",
    "    torch.load(r\"/Users/osinachinwogu/Documents/cybertruck/epoch10_11-28_10_50_06_66acc.pt\", map_location = device),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = face_model(x)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(face_model, \n",
    "                  x, \n",
    "                  'face_cnn.onnx',\n",
    "                  export_params=True, \n",
    "                  opset_version=17, \n",
    "                  do_constant_folding=True, \n",
    "                  input_names = ['input'], \n",
    "                  output_names = ['output'], \n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'}, 'output' : {0 : 'batch_size'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/osinachinwogu/miniforge3/envs/projenv/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnx_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Function `__call__` contains input name(s) x, y with unsupported characters which will be renamed to transpose_230_x, add_43_y in the SavedModel.\n",
      "INFO:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: face_cnn.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: face_cnn.tf/assets\n",
      "INFO:absl:Writing fingerprint to face_cnn.tf/fingerprint.pb\n"
     ]
    }
   ],
   "source": [
    "onnx_model = onnx.load('face_cnn.onnx')\n",
    "tf_model = onnx_tf.backend.prepare(onnx_model)\n",
    "tf_model.export_graph(\"face_cnn.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 18:46:34.444576: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-11-29 18:46:34.444780: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-11-29 18:46:34.445536: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: face_cnn.tf\n",
      "2023-11-29 18:46:34.461692: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-11-29 18:46:34.461713: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: face_cnn.tf\n",
      "2023-11-29 18:46:34.478957: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2023-11-29 18:46:34.481957: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-11-29 18:46:34.567298: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: face_cnn.tf\n",
      "2023-11-29 18:46:34.635855: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 190316 microseconds.\n",
      "2023-11-29 18:46:34.732749: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 132, Total Ops 363, % non-converted = 36.36 %\n",
      " * 132 ARITH ops\n",
      "\n",
      "- arith.constant:  132 occurrences  (i64: 1, f32: 123, i32: 8)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 12)\n",
      "  (f32: 40)\n",
      "  (f32: 34)\n",
      "  (f32: 1)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (i32: 2)\n",
      "  (f32: 34)\n",
      "  (f32: 4)\n",
      "  (i32: 1)\n",
      "  (f32: 11)\n",
      "  (f32: 2)\n",
      "  (i32: 2)\n",
      "  (i32: 2)\n",
      "  (f32: 78)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "83265428"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_converter = tf.lite.TFLiteConverter.from_saved_model(\"face_cnn.tf\")\n",
    "tflite_model = tf_converter.convert()\n",
    "open('face_cnn.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.04900261  0.25725016 -0.2126121  -0.3702479  -0.41028324 -1.0210481\n",
      "  -0.03697115  0.8536001   1.3789959  -0.49312112]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"face_cnn.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_input:0', 'index': 0, 'shape': array([  1,   3, 299, 299], dtype=int32), 'shape_signature': array([ -1,   3, 299, 299], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'PartitionedCall:0', 'index': 360, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "# Load the TFLite model in TFLite Interpreter\n",
    "interpreter = tf.lite.Interpreter(model_path=\"face_cnn.tflite\")\n",
    "\n",
    "# Resize input shape for dynamic shape model and allocate tensor\n",
    "interpreter.resize_tensor_input(interpreter.get_input_details()[0]['index'], [1, 3, 299, 299])\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(input_details) # Resized\n",
    "print(output_details)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, yaml\n",
    "from ultralytics import YOLO\n",
    "import torchvision\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "import os\n",
    "import onnx\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "root_dir = '/'.join(os.getcwd().split('/')[:-1])\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "\n",
    "from cnn.hands_cnn import Hands_VGG16\n",
    "from cnn.face_cnn import Face_CNN\n",
    "from cnn.raw_cnn import Raw_CNN\n",
    "from cnn.dataset import V2Dataset\n",
    "\n",
    "from wrappers.face_wrapper import Face_Inference_Wrapper\n",
    "from wrappers.hands_wrapper import Hands_Inference_Wrapper\n",
    "\n",
    "\n",
    "from ensemble import Ensemble_Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hands_path = (r\"/home/ron/Classes/CV-Systems/cybertruck/detection/hands_detection/runs/detect/best/weights/best.pt\")  # load a custom trained model\n",
    "face_path = (r\"/home/ron/Classes/CV-Systems/cybertruck/detection/face_detection/weights/yolov8n-face.pt\")  # load a custom trained model\n",
    "\n",
    "class HandArgs:\n",
    "    def __init__(self):\n",
    "        self.freeze = True\n",
    "        self.num_frozen_params = 30\n",
    "        self.dropout = 0.35\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "hand_args = HandArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = v2.Compose([\n",
    "        v2.ToPILImage(),\n",
    "        v2.Resize((299,299)),\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(mean=[0.3879, 0.3879, 0.3879], std=[0.3001, 0.3001, 0.3001])\n",
    "    ])\n",
    "\n",
    "val_dataset = V2Dataset(cam1_path=f'/home/ron/Classes/CV-Systems/cybertruck/data/v2_cam1_cam2_split_by_driver/Camera 1/test', cam2_path=f'/home/ron/Classes/CV-Systems/cybertruck/data/v2_cam1_cam2_split_by_driver/Camera 2/test', transform=test_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ron/miniconda3/envs/cyber/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name xception to current legacy_xception.\n",
      "  model = create_fn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "face_model = Face_CNN(None).to('cuda')\n",
    "x = torch.randn(5, 3, 299, 299).to('cuda')\n",
    "face_model.load_state_dict(torch.load(r\"/home/ron/Classes/CV-Systems/cybertruck/cnn/face_models/face/SGD/epoch10_11-28_10:50:06_66acc.pt\"))\n",
    "face_wrapper = Face_Inference_Wrapper(face_model, face_path)\n",
    "\n",
    "hands_model = Hands_VGG16(hand_args).to('cuda')\n",
    "x = torch.randn(5, 3, 224, 224).to('cuda')\n",
    "hands_model.load_state_dict(torch.load(r\"/home/ron/Classes/CV-Systems/cybertruck/cnn/hands_models/vgg/epoch60_11-16_03:44:44.pt\"))\n",
    "hands_wrapper = Hands_Inference_Wrapper(hands_model, hands_path)\n",
    "\n",
    "raw_model = Raw_CNN(None).to('cuda')\n",
    "x = torch.randn(5, 3, 299, 299).to('cuda')\n",
    "raw_model.load_state_dict(torch.load(r\"/home/ron/Classes/CV-Systems/cybertruck/cnn/raw_models/raw/SGD/epoch20_11-27_16:15:10_76acc.pt\"))\n",
    "raw_model.eval()\n",
    "\n",
    "model_list = [face_wrapper, hands_wrapper, raw_model]\n",
    "\n",
    "ensemble_model = Ensemble_Inference(hand_args, model_list, val_loader, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotSupportedError",
     "evalue": "Compiled functions can't take variable number of arguments or use keyword-only arguments with defaults:\n  File \"/home/ron/miniconda3/envs/cyber/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 30\n    def forward(self, x, *args, **kwargs):\n                                 ~~~~~~~ <--- HERE\n        \"\"\"\n        Forward pass of the model on a single scale. Wrapper for `_forward_once` method.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotSupportedError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ron/Classes/CV-Systems/cybertruck/conversions/ensemble_to_ptlite.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ron/Classes/CV-Systems/cybertruck/conversions/ensemble_to_ptlite.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m scripted_module \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mscript(ensemble_model)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ron/Classes/CV-Systems/cybertruck/conversions/ensemble_to_ptlite.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m torchscript_model_optimized \u001b[39m=\u001b[39m optimize_for_mobile(scripted_module)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ron/Classes/CV-Systems/cybertruck/conversions/ensemble_to_ptlite.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Export lite interpreter version model (compatible with lite interpreter)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cyber/lib/python3.10/site-packages/torch/jit/_script.py:1324\u001b[0m, in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m   1323\u001b[0m     obj \u001b[39m=\u001b[39m call_prepare_scriptable_func(obj)\n\u001b[0;32m-> 1324\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49m_recursive\u001b[39m.\u001b[39;49mcreate_script_module(\n\u001b[1;32m   1325\u001b[0m         obj, torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49m_recursive\u001b[39m.\u001b[39;49minfer_methods_to_compile\n\u001b[1;32m   1326\u001b[0m     )\n\u001b[1;32m   1327\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1328\u001b[0m     obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m__prepare_scriptable__() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m__prepare_scriptable__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m obj  \u001b[39m# type: ignore[operator]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cyber/lib/python3.10/site-packages/torch/jit/_recursive.py:559\u001b[0m, in \u001b[0;36mcreate_script_module\u001b[0;34m(nn_module, stubs_fn, share_types, is_tracing)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tracing:\n\u001b[1;32m    558\u001b[0m     AttributeTypeIsSupportedChecker()\u001b[39m.\u001b[39mcheck(nn_module)\n\u001b[0;32m--> 559\u001b[0m \u001b[39mreturn\u001b[39;00m create_script_module_impl(nn_module, concrete_type, stubs_fn)\n",
      "File \u001b[0;32m~/miniconda3/envs/cyber/lib/python3.10/site-packages/torch/jit/_recursive.py:632\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    629\u001b[0m     script_module\u001b[39m.\u001b[39m_concrete_type \u001b[39m=\u001b[39m concrete_type\n\u001b[1;32m    631\u001b[0m \u001b[39m# Actually create the ScriptModule, initializing it with the function we just defined\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m script_module \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mRecursiveScriptModule\u001b[39m.\u001b[39;49m_construct(cpp_module, init_fn)\n\u001b[1;32m    634\u001b[0m \u001b[39m# Compile methods if necessary\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m concrete_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m concrete_type_store\u001b[39m.\u001b[39mmethods_compiled:\n",
      "File \u001b[0;32m~/miniconda3/envs/cyber/lib/python3.10/site-packages/torch/jit/_script.py:639\u001b[0m, in \u001b[0;36mRecursiveScriptModule._construct\u001b[0;34m(cpp_module, init_fn)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[39mConstruct a RecursiveScriptModule that's ready for use. PyTorch\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[39mcode should use this to construct a RecursiveScriptModule instead\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[39m    init_fn:  Lambda that initializes the RecursiveScriptModule passed to it.\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    638\u001b[0m script_module \u001b[39m=\u001b[39m RecursiveScriptModule(cpp_module)\n\u001b[0;32m--> 639\u001b[0m init_fn(script_module)\n\u001b[1;32m    641\u001b[0m \u001b[39m# Finalize the ScriptModule: replace the nn.Module state with our\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[39m# custom implementations and flip the _initializing bit.\u001b[39;00m\n\u001b[1;32m    643\u001b[0m RecursiveScriptModule\u001b[39m.\u001b[39m_finalize_scriptmodule(script_module)\n",
      "File \u001b[0;32m~/miniconda3/envs/cyber/lib/python3.10/site-packages/torch/jit/_recursive.py:608\u001b[0m, in \u001b[0;36mcreate_script_module_impl.<locals>.init_fn\u001b[0;34m(script_module)\u001b[0m\n\u001b[1;32m    605\u001b[0m     scripted \u001b[39m=\u001b[39m orig_value\n\u001b[1;32m    606\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    607\u001b[0m     \u001b[39m# always reuse the provided stubs_fn to infer the methods to compile\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     scripted \u001b[39m=\u001b[39m create_script_module_impl(\n\u001b[1;32m    609\u001b[0m         orig_value, sub_concrete_type, stubs_fn\n\u001b[1;32m    610\u001b[0m     )\n\u001b[1;32m    612\u001b[0m cpp_module\u001b[39m.\u001b[39msetattr(name, scripted)\n\u001b[1;32m    613\u001b[0m script_module\u001b[39m.\u001b[39m_modules[name] \u001b[39m=\u001b[39m scripted\n",
      "File \u001b[0;32m~/miniconda3/envs/cyber/lib/python3.10/site-packages/torch/jit/_recursive.py:632\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    629\u001b[0m     script_module\u001b[39m.\u001b[39m_concrete_type \u001b[39m=\u001b[39m concrete_type\n\u001b[1;32m    631\u001b[0m \u001b[39m# Actually create the ScriptModule, initializing it with the function we just defined\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m script_module \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mRecursiveScriptModule\u001b[39m.\u001b[39;49m_construct(cpp_module, init_fn)\n\u001b[1;32m    634\u001b[0m \u001b[39m# Compile methods if necessary\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m concrete_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m concrete_type_store\u001b[39m.\u001b[39mmethods_compiled:\n",
      "File \u001b[0;32m~/miniconda3/envs/cyber/lib/python3.10/site-packages/torch/jit/_script.py:639\u001b[0m, in \u001b[0;36mRecursiveScriptModule._construct\u001b[0;34m(cpp_module, init_fn)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[39mConstruct a RecursiveScriptModule that's ready for use. PyTorch\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[39mcode should use this to construct a RecursiveScriptModule instead\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[39m    init_fn:  Lambda that initializes the RecursiveScriptModule passed to it.\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    638\u001b[0m script_module \u001b[39m=\u001b[39m RecursiveScriptModule(cpp_module)\n\u001b[0;32m--> 639\u001b[0m init_fn(script_module)\n\u001b[1;32m    641\u001b[0m \u001b[39m# Finalize the ScriptModule: replace the nn.Module state with our\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[39m# custom implementations and flip the _initializing bit.\u001b[39;00m\n\u001b[1;32m    643\u001b[0m RecursiveScriptModule\u001b[39m.\u001b[39m_finalize_scriptmodule(script_module)\n",
      "File \u001b[0;32m~/miniconda3/envs/cyber/lib/python3.10/site-packages/torch/jit/_recursive.py:608\u001b[0m, in \u001b[0;36mcreate_script_module_impl.<locals>.init_fn\u001b[0;34m(script_module)\u001b[0m\n\u001b[1;32m    605\u001b[0m     scripted \u001b[39m=\u001b[39m orig_value\n\u001b[1;32m    606\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    607\u001b[0m     \u001b[39m# always reuse the provided stubs_fn to infer the methods to compile\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     scripted \u001b[39m=\u001b[39m create_script_module_impl(\n\u001b[1;32m    609\u001b[0m         orig_value, sub_concrete_type, stubs_fn\n\u001b[1;32m    610\u001b[0m     )\n\u001b[1;32m    612\u001b[0m cpp_module\u001b[39m.\u001b[39msetattr(name, scripted)\n\u001b[1;32m    613\u001b[0m script_module\u001b[39m.\u001b[39m_modules[name] \u001b[39m=\u001b[39m scripted\n",
      "    \u001b[0;31m[... skipping similar frames: RecursiveScriptModule._construct at line 639 (1 times), create_script_module_impl at line 632 (1 times), create_script_module_impl.<locals>.init_fn at line 608 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cyber/lib/python3.10/site-packages/torch/jit/_recursive.py:632\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    629\u001b[0m     script_module\u001b[39m.\u001b[39m_concrete_type \u001b[39m=\u001b[39m concrete_type\n\u001b[1;32m    631\u001b[0m \u001b[39m# Actually create the ScriptModule, initializing it with the function we just defined\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m script_module \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mRecursiveScriptModule\u001b[39m.\u001b[39;49m_construct(cpp_module, init_fn)\n\u001b[1;32m    634\u001b[0m \u001b[39m# Compile methods if necessary\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m concrete_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m concrete_type_store\u001b[39m.\u001b[39mmethods_compiled:\n",
      "File \u001b[0;32m~/miniconda3/envs/cyber/lib/python3.10/site-packages/torch/jit/_script.py:639\u001b[0m, in \u001b[0;36mRecursiveScriptModule._construct\u001b[0;34m(cpp_module, init_fn)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[39mConstruct a RecursiveScriptModule that's ready for use. PyTorch\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[39mcode should use this to construct a RecursiveScriptModule instead\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[39m    init_fn:  Lambda that initializes the RecursiveScriptModule passed to it.\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    638\u001b[0m script_module \u001b[39m=\u001b[39m RecursiveScriptModule(cpp_module)\n\u001b[0;32m--> 639\u001b[0m init_fn(script_module)\n\u001b[1;32m    641\u001b[0m \u001b[39m# Finalize the ScriptModule: replace the nn.Module state with our\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[39m# custom implementations and flip the _initializing bit.\u001b[39;00m\n\u001b[1;32m    643\u001b[0m RecursiveScriptModule\u001b[39m.\u001b[39m_finalize_scriptmodule(script_module)\n",
      "File \u001b[0;32m~/miniconda3/envs/cyber/lib/python3.10/site-packages/torch/jit/_recursive.py:608\u001b[0m, in \u001b[0;36mcreate_script_module_impl.<locals>.init_fn\u001b[0;34m(script_module)\u001b[0m\n\u001b[1;32m    605\u001b[0m     scripted \u001b[39m=\u001b[39m orig_value\n\u001b[1;32m    606\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    607\u001b[0m     \u001b[39m# always reuse the provided stubs_fn to infer the methods to compile\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     scripted \u001b[39m=\u001b[39m create_script_module_impl(\n\u001b[1;32m    609\u001b[0m         orig_value, sub_concrete_type, stubs_fn\n\u001b[1;32m    610\u001b[0m     )\n\u001b[1;32m    612\u001b[0m cpp_module\u001b[39m.\u001b[39msetattr(name, scripted)\n\u001b[1;32m    613\u001b[0m script_module\u001b[39m.\u001b[39m_modules[name] \u001b[39m=\u001b[39m scripted\n",
      "File \u001b[0;32m~/miniconda3/envs/cyber/lib/python3.10/site-packages/torch/jit/_recursive.py:572\u001b[0m, in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39mConvert an nn.Module to a RecursiveScriptModule.\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39m    stubs_fn:  Lambda that takes an nn.Module and generates a list of ScriptMethodStubs to compile.\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    571\u001b[0m cpp_module \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_create_module_with_type(concrete_type\u001b[39m.\u001b[39mjit_type)\n\u001b[0;32m--> 572\u001b[0m method_stubs \u001b[39m=\u001b[39m stubs_fn(nn_module)\n\u001b[1;32m    573\u001b[0m property_stubs \u001b[39m=\u001b[39m get_property_stubs(nn_module)\n\u001b[1;32m    574\u001b[0m hook_stubs, pre_hook_stubs \u001b[39m=\u001b[39m get_hook_stubs(nn_module)\n",
      "File \u001b[0;32m~/miniconda3/envs/cyber/lib/python3.10/site-packages/torch/jit/_recursive.py:899\u001b[0m, in \u001b[0;36minfer_methods_to_compile\u001b[0;34m(nn_module)\u001b[0m\n\u001b[1;32m    897\u001b[0m stubs \u001b[39m=\u001b[39m []\n\u001b[1;32m    898\u001b[0m \u001b[39mfor\u001b[39;00m method \u001b[39min\u001b[39;00m uniqued_methods:\n\u001b[0;32m--> 899\u001b[0m     stubs\u001b[39m.\u001b[39mappend(make_stub_from_method(nn_module, method))\n\u001b[1;32m    900\u001b[0m \u001b[39mreturn\u001b[39;00m overload_stubs \u001b[39m+\u001b[39m stubs\n",
      "File \u001b[0;32m~/miniconda3/envs/cyber/lib/python3.10/site-packages/torch/jit/_recursive.py:87\u001b[0m, in \u001b[0;36mmake_stub_from_method\u001b[0;34m(nn_module, method_name)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[39mreturn\u001b[39;00m func\n\u001b[1;32m     79\u001b[0m \u001b[39m# Make sure the name present in the resulting AST will match the name\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[39m# requested here. The only time they don't match is if you do something\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39m# like:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39m# In this case, the actual function object will have the name `_forward`,\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[39m# even though we requested a stub for `forward`.\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m \u001b[39mreturn\u001b[39;00m make_stub(func, method_name)\n",
      "File \u001b[0;32m~/miniconda3/envs/cyber/lib/python3.10/site-packages/torch/jit/_recursive.py:71\u001b[0m, in \u001b[0;36mmake_stub\u001b[0;34m(func, name)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_stub\u001b[39m(func, name):\n\u001b[1;32m     70\u001b[0m     rcb \u001b[39m=\u001b[39m _jit_internal\u001b[39m.\u001b[39mcreateResolutionCallbackFromClosure(func)\n\u001b[0;32m---> 71\u001b[0m     ast \u001b[39m=\u001b[39m get_jit_def(func, name, self_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mRecursiveScriptModule\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m ScriptMethodStub(rcb, ast, func)\n",
      "File \u001b[0;32m~/miniconda3/envs/cyber/lib/python3.10/site-packages/torch/jit/frontend.py:372\u001b[0m, in \u001b[0;36mget_jit_def\u001b[0;34m(fn, def_name, self_name, is_classmethod)\u001b[0m\n\u001b[1;32m    369\u001b[0m     qualname \u001b[39m=\u001b[39m get_qualified_name(fn)\n\u001b[1;32m    370\u001b[0m     pdt_arg_types \u001b[39m=\u001b[39m type_trace_db\u001b[39m.\u001b[39mget_args_types(qualname)\n\u001b[0;32m--> 372\u001b[0m \u001b[39mreturn\u001b[39;00m build_def(\n\u001b[1;32m    373\u001b[0m     parsed_def\u001b[39m.\u001b[39;49mctx,\n\u001b[1;32m    374\u001b[0m     fn_def,\n\u001b[1;32m    375\u001b[0m     type_line,\n\u001b[1;32m    376\u001b[0m     def_name,\n\u001b[1;32m    377\u001b[0m     self_name\u001b[39m=\u001b[39;49mself_name,\n\u001b[1;32m    378\u001b[0m     pdt_arg_types\u001b[39m=\u001b[39;49mpdt_arg_types,\n\u001b[1;32m    379\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/cyber/lib/python3.10/site-packages/torch/jit/frontend.py:422\u001b[0m, in \u001b[0;36mbuild_def\u001b[0;34m(ctx, py_def, type_line, def_name, self_name, pdt_arg_types)\u001b[0m\n\u001b[1;32m    419\u001b[0m body \u001b[39m=\u001b[39m py_def\u001b[39m.\u001b[39mbody\n\u001b[1;32m    420\u001b[0m r \u001b[39m=\u001b[39m ctx\u001b[39m.\u001b[39mmake_range(py_def\u001b[39m.\u001b[39mlineno, py_def\u001b[39m.\u001b[39mcol_offset, py_def\u001b[39m.\u001b[39mcol_offset \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mdef\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m--> 422\u001b[0m param_list \u001b[39m=\u001b[39m build_param_list(ctx, py_def\u001b[39m.\u001b[39;49margs, self_name, pdt_arg_types)\n\u001b[1;32m    423\u001b[0m return_type \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(py_def, \u001b[39m\"\u001b[39m\u001b[39mreturns\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cyber/lib/python3.10/site-packages/torch/jit/frontend.py:448\u001b[0m, in \u001b[0;36mbuild_param_list\u001b[0;34m(ctx, py_args, self_name, pdt_arg_types)\u001b[0m\n\u001b[1;32m    444\u001b[0m     expr \u001b[39m=\u001b[39m py_args\u001b[39m.\u001b[39mkwarg\n\u001b[1;32m    445\u001b[0m     ctx_range \u001b[39m=\u001b[39m ctx\u001b[39m.\u001b[39mmake_range(\n\u001b[1;32m    446\u001b[0m         expr\u001b[39m.\u001b[39mlineno, expr\u001b[39m.\u001b[39mcol_offset \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, expr\u001b[39m.\u001b[39mcol_offset \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(expr\u001b[39m.\u001b[39marg)\n\u001b[1;32m    447\u001b[0m     )\n\u001b[0;32m--> 448\u001b[0m     \u001b[39mraise\u001b[39;00m NotSupportedError(ctx_range, _vararg_kwarg_err)\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m py_args\u001b[39m.\u001b[39mvararg \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    450\u001b[0m     expr \u001b[39m=\u001b[39m py_args\u001b[39m.\u001b[39mvararg\n",
      "\u001b[0;31mNotSupportedError\u001b[0m: Compiled functions can't take variable number of arguments or use keyword-only arguments with defaults:\n  File \"/home/ron/miniconda3/envs/cyber/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 30\n    def forward(self, x, *args, **kwargs):\n                                 ~~~~~~~ <--- HERE\n        \"\"\"\n        Forward pass of the model on a single scale. Wrapper for `_forward_once` method.\n"
     ]
    }
   ],
   "source": [
    "scripted_module = torch.jit.script(ensemble_model)\n",
    "torchscript_model_optimized = optimize_for_mobile(scripted_module)\n",
    "# Export lite interpreter version model (compatible with lite interpreter)\n",
    "scripted_module._save_for_lite_interpreter(\"Ensemble.ptl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

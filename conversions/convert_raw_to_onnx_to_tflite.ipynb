{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Hands CNN and Detector from ONNX to TFLite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hands CNN + Detector Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import onnx_tf\n",
    "import onnx\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"D:\\Programming\\cybertruck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'raw_cnn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Prepare the Onnx model for tensorflow and then convert to tflite\n",
    "\n",
    "https://medium.com/@zergtant/convert-pytorch-model-to-tf-lite-with-onnx-tf-232a3894657c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_onnx_to_tflite(model_name):\n",
    "    # Load  ONNX model\n",
    "    onnx_model = onnx.load(f'{model_name}.onnx')\n",
    "\n",
    "    # Convert ONNX model to TensorFlow format\n",
    "    tf_model = onnx_tf.backend.prepare(onnx_model)\n",
    "    # Export  TensorFlow  model \n",
    "    tf_model.export_graph(f'{model_name}.tf')\n",
    "\n",
    "    # Then convert from TF to TFLite\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(f'{model_name}.tf')\n",
    "    tflite_model = converter.convert()\n",
    "    open(f'{model_name}.tflite', 'wb').write(tflite_model)\n",
    "\n",
    "convert_onnx_to_tflite(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now test the converted model\n",
    "\n",
    "https://www.tensorflow.org/lite/guide/inference\n",
    "https://www.tensorflow.org/lite/guide/inference#run_inference_with_dynamic_shape_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that by default, this model takes a batch size of 1. Which works out well since we want real time performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tflite_model(model_name):\n",
    "    model_filename = f\"{model_name}.tflite\"\n",
    "\n",
    "    # Load the TFLite model and allocate tensors.\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_filename)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    # Test the model on random input data.\n",
    "    input_shape = input_details[0]['shape']\n",
    "    print(input_shape)\n",
    "    input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # The function `get_tensor()` returns a copy of the tensor data.\n",
    "    # Use `tensor()` in order to get a pointer to the tensor.\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    print(output_data)\n",
    "\n",
    "test_tflite_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dynamic_batches_tflite(model_name):\n",
    "    model_filename = f\"{model_name}.tflite\"\n",
    "\n",
    "    # Load the TFLite model in TFLite Interpreter\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_filename)\n",
    "\n",
    "    input_shape = interpreter.get_input_details()[0]['shape']\n",
    "    input_shape[0] = 5 # Set to batch size of 5 instead of the default 1\n",
    "\n",
    "    # Resize input shape for dynamic shape model and allocate tensor\n",
    "    interpreter.resize_tensor_input(interpreter.get_input_details()[0]['index'], input_shape)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    print(input_details) # Here we can see the input size has changed to (5, 3, 299, 299) \n",
    "    print(output_details) # The output has the corresponding changes\n",
    "\n",
    "    input_data = np.array(np.random.random_sample((5, 3, 224, 224)), dtype=np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    print(output_data)\n",
    "\n",
    "test_dynamic_batches_tflite(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting CNNs to Pytorch Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ron/Classes/CV-Systems/cybertruck\n",
      "['/home/ron/Classes/CV-Systems/cybertruck/conversions', '/home/ron/miniconda3/envs/cyber/lib/python310.zip', '/home/ron/miniconda3/envs/cyber/lib/python3.10', '/home/ron/miniconda3/envs/cyber/lib/python3.10/lib-dynload', '', '/home/ron/.local/lib/python3.10/site-packages', '/home/ron/miniconda3/envs/cyber/lib/python3.10/site-packages', '/home/ron/Classes/CV-Systems/cybertruck']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "\n",
    "\n",
    "root_dir = '/'.join(os.getcwd().split('/')[:-1])\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "from cnn.raw_cnn import Raw_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ron/miniconda3/envs/cyber/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name xception to current legacy_xception.\n",
      "  model = create_fn(\n"
     ]
    }
   ],
   "source": [
    "raw_model = Raw_CNN(None).to('cuda')\n",
    "x = torch.randn(5, 3, 299, 299).to('cuda')\n",
    "raw_model.load_state_dict(torch.load(r\"/home/ron/Classes/CV-Systems/cybertruck/cnn/raw_models/raw/SGD/epoch20_11-27_16:15:10_76acc.pt\"))\n",
    "raw_model.eval()\n",
    "\n",
    "\n",
    "scripted_module = torch.jit.script(raw_model)\n",
    "torchscript_model_optimized = optimize_for_mobile(scripted_module)\n",
    "# Export lite interpreter version model (compatible with lite interpreter)\n",
    "scripted_module._save_for_lite_interpreter(\"RAW_CNN.ptl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert PyTorch to ONNX to TFLite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAW CNN Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Developer\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"D:\\Programming\\cybertruck\")\n",
    "\n",
    "from cnn.raw_cnn import Raw_CNN\n",
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Developer\\Python310\\lib\\site-packages\\timm\\models\\_factory.py:117: UserWarning: Mapping deprecated model name xception to current legacy_xception.\n",
      "  model = create_fn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_model = Raw_CNN(None).to('cuda')\n",
    "x = torch.randn(5, 3, 299, 299).to('cuda')\n",
    "raw_model.load_state_dict(torch.load(r\"D:\\Programming\\cybertruck\\weights\\raw\\epoch20_11-27_16_15_10_76acc.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = raw_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(raw_model, \n",
    "                  x, \n",
    "                  'raw_cnn.onnx',\n",
    "                  export_params=True, \n",
    "                  opset_version=17, \n",
    "                  do_constant_folding=True, \n",
    "                  input_names = ['input'], \n",
    "                  output_names = ['output'], \n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'}, 'output' : {0 : 'batch_size'}})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Prepare the Onnx model for tensorflow and then convert to tflite\n",
    "\n",
    "https://medium.com/@zergtant/convert-pytorch-model-to-tf-lite-with-onnx-tf-232a3894657c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Developer\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Developer\\Python310\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Developer\\Python310\\lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Developer\\Python310\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Developer\\Python310\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.15.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Developer\\Python310\\lib\\site-packages\\keras\\src\\utils\\version_utils.py:76: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Function `__call__` contains input name(s) x, y with unsupported characters which will be renamed to transpose_230_x, add_43_y in the SavedModel.\n",
      "INFO:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: raw_cnn.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: raw_cnn.tf\\assets\n",
      "INFO:absl:Writing fingerprint to raw_cnn.tf\\fingerprint.pb\n"
     ]
    }
   ],
   "source": [
    "import onnx_tf\n",
    "import onnx\n",
    "\n",
    "# Load  ONNX model\n",
    "onnx_model = onnx.load('raw_cnn.onnx')\n",
    "\n",
    "# Convert ONNX model to TensorFlow format\n",
    "tf_model = onnx_tf.backend.prepare(onnx_model)\n",
    "# Export  TensorFlow  model \n",
    "tf_model.export_graph(\"raw_cnn.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83265428"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"raw_cnn.tf\")\n",
    "tflite_model = converter.convert()\n",
    "open('raw_cnn.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now test the converted model\n",
    "\n",
    "https://www.tensorflow.org/lite/guide/inference\n",
    "https://www.tensorflow.org/lite/guide/inference#run_inference_with_dynamic_shape_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that by default, this model takes a batch size of 1. Which works out well since we want real time performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   3 299 299]\n",
      "[[ 0.20226912  0.71003246 -0.25777435 -0.03049688 -1.0173109  -0.30656993\n",
      "  -0.00746293  0.36016852  0.60894096 -0.45594865]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"raw_cnn.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "print(input_shape)\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_input:0', 'index': 0, 'shape': array([  5,   3, 299, 299]), 'shape_signature': array([ -1,   3, 299, 299]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'PartitionedCall:0', 'index': 360, 'shape': array([ 1, 10]), 'shape_signature': array([-1, 10]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[[ 0.20618625  0.6512822  -0.22456828 -0.02333656 -1.0345409  -0.35443354\n",
      "  -0.0610419   0.35702717  0.65950936 -0.386321  ]\n",
      " [ 0.18873031  0.6354935  -0.23225972  0.00843845 -0.9819105  -0.27088338\n",
      "  -0.04604215  0.31904203  0.57895863 -0.388857  ]\n",
      " [ 0.1368683   0.70485806 -0.21472725 -0.00438199 -0.9849346  -0.33788514\n",
      "   0.01212354  0.36223304  0.53291494 -0.43008518]\n",
      " [ 0.21859439  0.6477699  -0.22221784  0.01216426 -0.96966094 -0.3585875\n",
      "  -0.01702444  0.28348124  0.56722623 -0.3970083 ]\n",
      " [ 0.1918393   0.6760634  -0.19343053 -0.02171362 -1.013835   -0.31794608\n",
      "  -0.04987581  0.37724382  0.5759724  -0.4063682 ]]\n"
     ]
    }
   ],
   "source": [
    "# Load the TFLite model in TFLite Interpreter\n",
    "interpreter = tf.lite.Interpreter(model_path=\"raw_cnn.tflite\")\n",
    "\n",
    "# Resize input shape for dynamic shape model and allocate tensor\n",
    "interpreter.resize_tensor_input(interpreter.get_input_details()[0]['index'], [5, 3, 299, 299])\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(input_details) # Here we can see the input size has changed to (5, 3, 299, 299) \n",
    "print(output_details) # The output has the corresponding changes\n",
    "\n",
    "input_data = np.array(np.random.random_sample((5, 3, 299, 299)), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

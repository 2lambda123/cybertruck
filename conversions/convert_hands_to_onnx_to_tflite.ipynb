{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Hands CNN and Detector from ONNX to TFLite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hands CNN + Detector Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import onnx_tf\n",
    "import onnx\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"D:\\Programming\\cybertruck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'hands_detector'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Prepare the Onnx model for tensorflow and then convert to tflite\n",
    "\n",
    "https://medium.com/@zergtant/convert-pytorch-model-to-tf-lite-with-onnx-tf-232a3894657c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_onnx_to_tflite(model_name):\n",
    "    # Load  ONNX model\n",
    "    onnx_model = onnx.load(f'{model_name}.onnx')\n",
    "\n",
    "    # Convert ONNX model to TensorFlow format\n",
    "    tf_model = onnx_tf.backend.prepare(onnx_model)\n",
    "    # Export  TensorFlow  model \n",
    "    tf_model.export_graph(f'{model_name}.tf')\n",
    "\n",
    "    # Then convert from TF to TFLite\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(f'{model_name}.tf')\n",
    "    tflite_model = converter.convert()\n",
    "    open(f'{model_name}.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now test the converted model\n",
    "\n",
    "https://www.tensorflow.org/lite/guide/inference\n",
    "https://www.tensorflow.org/lite/guide/inference#run_inference_with_dynamic_shape_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that by default, this model takes a batch size of 1. Which works out well since we want real time performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   3 224 224]\n",
      "[[ 0.38875434 -0.27507943 -0.48259985 -0.04473732  0.13935351 -0.16089939\n",
      "   0.00969524  0.24680549  0.30112687  0.10554482]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"hands_cnn.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "print(input_shape)\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'serving_default_input:0', 'index': 0, 'shape': array([  5,   3, 224, 224]), 'shape_signature': array([ -1,   3, 299, 299]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'PartitionedCall:0', 'index': 360, 'shape': array([ 1, 10]), 'shape_signature': array([-1, 10]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[[ 0.62110627  1.277077   -0.34690422 -0.1362839  -2.0667741  -0.65724695\n",
      "  -0.00231836  0.6305507   1.2859055  -0.79382193]\n",
      " [ 0.62159884  1.2866197  -0.27352217 -0.14923137 -2.018711   -0.6308625\n",
      "  -0.03146842  0.60975784  1.1814307  -0.7074548 ]\n",
      " [ 0.54732144  1.1805639  -0.34844688 -0.11515829 -1.9153498  -0.5589704\n",
      "  -0.08506137  0.62703127  1.1366704  -0.63647485]\n",
      " [ 0.5867675   1.0879285  -0.3068053  -0.17769586 -1.8913159  -0.5666297\n",
      "  -0.03757305  0.5883057   1.2088557  -0.7158476 ]\n",
      " [ 0.61520827  1.3187275  -0.3165068  -0.10562398 -2.0329807  -0.5713333\n",
      "  -0.0948936   0.5742936   1.1000255  -0.72248644]]\n"
     ]
    }
   ],
   "source": [
    "# Load the TFLite model in TFLite Interpreter\n",
    "interpreter = tf.lite.Interpreter(model_path=\"raw_cnn.tflite\")\n",
    "\n",
    "# Resize input shape for dynamic shape model and allocate tensor\n",
    "interpreter.resize_tensor_input(interpreter.get_input_details()[0]['index'], [5, 3, 224 , 224])\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(input_details) # Here we can see the input size has changed to (5, 3, 299, 299) \n",
    "print(output_details) # The output has the corresponding changes\n",
    "\n",
    "input_data = np.array(np.random.random_sample((5, 3, 224, 224)), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
